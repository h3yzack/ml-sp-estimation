{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 600\n",
    "LEARNING_RATE = 1e-4\n",
    "MAX_LENGTH = 256\n",
    "BASE_MODEL = \"roberta-base\"\n",
    "vocab = 10000\n",
    "\n",
    "case = \"Case_M\"\n",
    "code = f\"20x1_{case}\"\n",
    "dataset_splitted_path = f\"datasets/{case}\"\n",
    "models_path = f\"models/{case}/{code}\"\n",
    "\n",
    "\n",
    "batch_1 = ['APSTUD', 'BAM', 'CLOV', 'DM']\n",
    "batch_2 = ['DURACLOUD', 'JRESERVER', 'MDL', 'MESOS']\n",
    "batch_3 = ['MULE', 'MULESTUDIO', 'TIMOB']\n",
    "batch_4 = ['TISTUD', 'USERGRID', 'XD']\n",
    "\n",
    "# combine all datasets\n",
    "dataset_names = batch_1 + batch_2 + batch_3 + batch_4\n",
    "\n",
    "project_names = ['AS', 'BB', 'CV', 'DM', 'DC', 'JS', 'MD', 'ME', 'MU', 'MS', 'AP', 'TS', 'UG', 'XD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "import torch\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer as KerasTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "\n",
    "class MakeTorchData(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        item[\"labels\"] = float(item[\"labels\"])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class RobertaRegressorWrapper:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.trainer = None\n",
    "        self.built = True\n",
    "        self.initFit()\n",
    "\n",
    "    def initFit(self):\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f'{self.model_path}/ensemble',\n",
    "            per_device_eval_batch_size=BATCH_SIZE,\n",
    "        )\n",
    "\n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            compute_metrics=compute_eval_metrics,  # Add your own metrics function here if needed\n",
    "        )\n",
    "\n",
    "        # self.trainer.train()\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.trainer.eval_dataset = X\n",
    "        predictions = self.trainer.predict(X).predictions\n",
    "        return predictions\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"model_path\": self.model_path}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return mean_absolute_error(y, predictions)\n",
    "\n",
    "\n",
    "class BiLSTMRegressorWrapper:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        self.model = load_model(model_path)\n",
    "        self.built = True\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        # optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "        # self.model.compile(optimizer=optimizer, loss='mae', metrics=['mae'])\n",
    "        # self.model.fit(X, y, **kwargs)\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X).flatten()\n",
    "    \n",
    "def get_max_len(data, tokernizer):\n",
    "    tokernizer.fit_on_texts(data)\n",
    "    sequence_combined = tokernizer.texts_to_sequences(data)\n",
    "    max_len = max([len(x) for x in sequence_combined])\n",
    "    return max_len\n",
    "\n",
    "def compute_eval_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    mdae = median_absolute_error(labels, logits)\n",
    "    return {\"mae\": mae, \"mdae\": mdae}\n",
    "\n",
    "def preprocess_function(examples, tokernizer):\n",
    "    encoded = tokernizer(examples['text'], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n",
    "    dataset = MakeTorchData(encoded, examples['storypoint'])\n",
    "    return dataset\n",
    "\n",
    "def load_dataset(dataset_name):\n",
    "    raw_train_data = Dataset.from_json(f'{dataset_splitted_path}/{dataset_name}/train.json')\n",
    "    raw_val_data = Dataset.from_json(f'{dataset_splitted_path}/{dataset_name}/val.json')\n",
    "    raw_test_data = Dataset.from_json(f'{dataset_splitted_path}/{dataset_name}/test.json')\n",
    "\n",
    "    return raw_train_data, raw_val_data, raw_test_data\n",
    "\n",
    "def load_dataset_type(dataset_name, dataset_type):\n",
    "    raw_data = Dataset.from_json(f'{dataset_splitted_path}/{dataset_name}/{dataset_type}.json')\n",
    "    return raw_data\n",
    "\n",
    "def load_models(dataset_name):\n",
    "    bilstm_model_path = f'{models_path}/bilstm/{dataset_name}/{dataset_name}.keras'\n",
    "    roberta_model_path = f'{models_path}/roberta/{dataset_name}/model'\n",
    "\n",
    "    bilstm_wrapper = BiLSTMRegressorWrapper(bilstm_model_path)\n",
    "    roberta_wrapper = RobertaRegressorWrapper(roberta_model_path)\n",
    "\n",
    "    return bilstm_wrapper, roberta_wrapper\n",
    "\n",
    "def get_padding_sequence(data, tokenizer, max_len):\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "    padded_seq = pad_sequences(sequences, maxlen=max_len, dtype='int32', padding='pre',truncating='pre', value=0)\n",
    "    return padded_seq\n",
    "\n",
    "def get_meta_model():\n",
    "    meta_model = Sequential()\n",
    "    meta_model.add(Dense(10, input_dim=2, activation='relu'))  # Assuming you have 2 base models\n",
    "    meta_model.add(Dense(10, activation='relu'))  # Additional Dense layer\n",
    "    meta_model.add(Dense(1, activation='linear'))  # Final Dense layer with activation function\n",
    "\n",
    "    # Compile the meta-model\n",
    "    optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "    # optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE)\n",
    "    meta_model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
    "\n",
    "    return meta_model\n",
    "\n",
    "def load_meta_model(dataset_name):\n",
    "    meta_model_path = f'{models_path}/meta-model/{dataset_name}/{dataset_name}.keras'\n",
    "    meta_model = load_model(meta_model_path)\n",
    "    return meta_model\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "bilstm_tokenizer = KerasTokenizer(num_words=vocab, oov_token=0)\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"start processing - {dataset_name}...\")\n",
    "    os.makedirs(f'{models_path}/meta-model/{dataset_name}', exist_ok=True)\n",
    "\n",
    "    # load models\n",
    "    bilstm_model, roberta_model = load_models(dataset_name)\n",
    "\n",
    "    # load dataset\n",
    "    raw_train_data, raw_val_data, raw_test_data = load_dataset(dataset_name)\n",
    "\n",
    "    # calculate the max length of the sequences\n",
    "    max_len = get_max_len(pd.concat([pd.Series(raw_train_data['text']), pd.Series(raw_val_data['text'])]), bilstm_tokenizer)\n",
    "    print(f\"max_len: {max_len}\")\n",
    "\n",
    "    # convert raw_train_data to a DataFrame if it's not already\n",
    "    if not isinstance(raw_train_data, pd.DataFrame):\n",
    "        raw_train_data = pd.DataFrame(raw_train_data)\n",
    "\n",
    "    meta_model_inputs = []\n",
    "    meta_model_targets = []\n",
    "\n",
    "    for train_index, val_index in kf.split(raw_train_data):\n",
    "        # Split the data\n",
    "        raw_train_data_fold = raw_train_data.iloc[train_index]\n",
    "        raw_val_data_fold = raw_train_data.iloc[val_index]\n",
    "\n",
    "        # prepare for the RoBERTa model\n",
    "        roberta_train_data = preprocess_function(raw_train_data_fold.to_dict('list'), roberta_tokenizer)\n",
    "        roberta_val_data = preprocess_function(raw_val_data_fold.to_dict('list'), roberta_tokenizer)\n",
    "\n",
    "        # prepare for the BiLSTM model\n",
    "        train_data = pd.Series(raw_train_data_fold['text'])\n",
    "        train_padded_seq = get_padding_sequence(train_data, bilstm_tokenizer, max_len)\n",
    "        val_data = pd.Series(raw_val_data_fold['text'])\n",
    "        val_padded_seq = get_padding_sequence(val_data, bilstm_tokenizer, max_len)\n",
    "\n",
    "        # predict on validation fold\n",
    "        roberta_val_preds = roberta_model.predict(roberta_val_data)\n",
    "        bilstm_val_preds = bilstm_model.predict(val_padded_seq)\n",
    "\n",
    "        # Stack the predictions together\n",
    "        val_preds_meta = np.column_stack((roberta_val_preds, bilstm_val_preds))\n",
    "\n",
    "        # Add the predictions and targets to the lists\n",
    "        meta_model_inputs.append(val_preds_meta)\n",
    "        meta_model_targets.append(raw_val_data_fold['storypoint'])\n",
    "\n",
    "    # Concatenate all the predictions and targets\n",
    "    meta_model_inputs = np.concatenate(meta_model_inputs)\n",
    "    meta_model_targets = np.concatenate(meta_model_targets)\n",
    "\n",
    "    meta_model = get_meta_model()\n",
    "\n",
    "    # Define the checkpoint path and filename\n",
    "    checkpoint_filepath = f'{models_path}/meta-model/{dataset_name}/checkpoint'\n",
    "\n",
    "    # Create a ModelCheckpoint callback that saves the weights only of the best model observed as per the validation data\n",
    "    model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True)\n",
    "    \n",
    "    # Prepare the validation data for the base models\n",
    "    eval_label = pd.Series(raw_val_data['storypoint']).astype(float)\n",
    "    roberta_val_data = preprocess_function(raw_val_data, roberta_tokenizer)\n",
    "    val_padded_seq = get_padding_sequence(pd.Series(raw_val_data['text']), bilstm_tokenizer, max_len)\n",
    "\n",
    "    # Generate predictions from the base models on the validation set\n",
    "    roberta_val_preds = roberta_model.predict(roberta_val_data)\n",
    "    bilstm_val_preds = bilstm_model.predict(val_padded_seq)\n",
    "\n",
    "    # Stack the predictions together\n",
    "    val_preds_meta = np.column_stack((roberta_val_preds, bilstm_val_preds))\n",
    "\n",
    "    # Fit the model with the new callback\n",
    "    history = meta_model.fit(meta_model_inputs, meta_model_targets, validation_data=(val_preds_meta, eval_label), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=3), model_checkpoint_callback])\n",
    "\n",
    "    # Load the weights of the best model observed during training\n",
    "    meta_model.load_weights(checkpoint_filepath)\n",
    "\n",
    "    # save the meta model\n",
    "    meta_model.save(f'{models_path}/meta-model/{dataset_name}/{dataset_name}.keras')\n",
    "\n",
    "    \n",
    "    val_loss, val_mae =  meta_model.evaluate(val_preds_meta, eval_label)\n",
    "    print(f\"val_loss: {val_loss}, val_mae: {val_mae}\")\n",
    "\n",
    "    # if 1 == 1:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "bilstm_tokenizer = KerasTokenizer(num_words=vocab, oov_token=0)\n",
    "\n",
    "results = []\n",
    "residuals_all = []\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"start processing - {dataset_name}...\")\n",
    "\n",
    "    # get project name\n",
    "    project_name = project_names[dataset_names.index(dataset_name)]\n",
    "\n",
    "    # load models\n",
    "    bilstm_model, roberta_model = load_models(dataset_name)\n",
    "    meta_model = load_meta_model(dataset_name)\n",
    "\n",
    "    # load dataset\n",
    "    raw_train_data, raw_val_data, raw_test_data = load_dataset(dataset_name)\n",
    "\n",
    "    # calculate the max length of the sequences\n",
    "    max_len = get_max_len(pd.concat([pd.Series(raw_train_data['text']), pd.Series(raw_val_data['text'])]), bilstm_tokenizer)\n",
    "    print(f\"max_len: {max_len}\")\n",
    "\n",
    "    # Prepare the validation data for the base models\n",
    "    eval_label = pd.Series(raw_val_data['storypoint']).astype(float)\n",
    "    roberta_val_data = preprocess_function(raw_val_data, roberta_tokenizer)\n",
    "    val_padded_seq = get_padding_sequence(pd.Series(raw_val_data['text']), bilstm_tokenizer, max_len)\n",
    "\n",
    "    # Generate predictions from the base models on the validation set\n",
    "    roberta_val_preds = roberta_model.predict(roberta_val_data)\n",
    "    bilstm_val_preds = bilstm_model.predict(val_padded_seq)\n",
    "\n",
    "    # calculate MAPE for each model\n",
    "    roberta_val_preds_flat = roberta_val_preds.flatten()\n",
    "    mape_roberta = np.mean(np.abs((eval_label - roberta_val_preds_flat) / eval_label))\n",
    "    mape_bilstm = np.mean(np.abs((eval_label - bilstm_val_preds) / eval_label))\n",
    "\n",
    "    print(f\"MAPE RoBERTa: {mape_roberta}\")\n",
    "    print(f\"MAPE BiLSTM: {mape_bilstm}\")\n",
    "\n",
    "    # Stack the predictions together\n",
    "    val_preds_meta = np.column_stack((roberta_val_preds, bilstm_val_preds))\n",
    "\n",
    "    stacking_pred_nn = meta_model.predict(val_preds_meta)\n",
    "\n",
    "    # save the predictions\n",
    "    np.save(f'{models_path}/meta-model/{dataset_name}/{dataset_name}_val_pred.npy', stacking_pred_nn)\n",
    "\n",
    "    # Calculate the MAE and MdAE\n",
    "    mae_nn = mean_absolute_error(eval_label, stacking_pred_nn)\n",
    "    mdae_nn = median_absolute_error(eval_label, stacking_pred_nn)\n",
    "    print(f\"NN Staking MdAE: {mdae_nn}\")\n",
    "    print(f\"NN Staking MAE: {mae_nn}\")\n",
    "    print(f\"Finish process {dataset_name}\")\n",
    "\n",
    "    val_storypoint = raw_val_data['storypoint']\n",
    "    # Standard Deviation of Residuals\n",
    "    std_dev = np.std(val_storypoint - stacking_pred_nn)\n",
    "\n",
    "    # Calculate the percentage error for each prediction\n",
    "    percentage_errors = (val_storypoint - stacking_pred_nn) / val_storypoint\n",
    "\n",
    "    # Calculate the mean percentage error\n",
    "    mpe = np.mean(percentage_errors)\n",
    "\n",
    "    # calculate the Mean Absolute Percentage Error\n",
    "    mape = np.mean(np.abs(percentage_errors))\n",
    "    \n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'project_name': project_name,\n",
    "        'mae': mae_nn,\n",
    "        'mdae': mdae_nn,\n",
    "        'std_dev': std_dev,\n",
    "        'mpe': mpe,\n",
    "        'mape_stack': mape,\n",
    "        'mape_roberta': mape_roberta,\n",
    "        'mape_bilstm': mape_bilstm\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "\n",
    "    # if 1 == 1:\n",
    "    #     break\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(f'{models_path}/meta-model/results.csv', index=False)\n",
    "   \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "roberta_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "bilstm_tokenizer = KerasTokenizer(num_words=vocab, oov_token=0)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"Processing test predictions for {dataset_name}...\")\n",
    "\n",
    "    # Load models\n",
    "    bilstm_model, roberta_model = load_models(dataset_name)\n",
    "    meta_model = load_meta_model(dataset_name)\n",
    "\n",
    "    # Load dataset\n",
    "    raw_train_data, raw_val_data, raw_test_data = load_dataset(dataset_name)\n",
    "\n",
    "    # Calculate max_len as used in training\n",
    "    max_len = get_max_len(\n",
    "        pd.concat([pd.Series(raw_train_data['text']),\n",
    "                   pd.Series(raw_val_data['text'])]),\n",
    "        bilstm_tokenizer\n",
    "    )\n",
    "\n",
    "    # Prepare test data for base models\n",
    "    test_label = pd.Series(raw_test_data['storypoint']).astype(float)\n",
    "    roberta_test_data = preprocess_function(raw_test_data, roberta_tokenizer)\n",
    "    test_padded_seq = get_padding_sequence(\n",
    "        pd.Series(raw_test_data['text']),\n",
    "        bilstm_tokenizer,\n",
    "        max_len\n",
    "    )\n",
    "\n",
    "    # Generate predictions from base models on the test set\n",
    "    roberta_test_preds = roberta_model.predict(roberta_test_data).flatten()\n",
    "    bilstm_test_preds = bilstm_model.predict(test_padded_seq).flatten()\n",
    "\n",
    "    # Stack the predictions together\n",
    "    test_preds_meta = np.column_stack((roberta_test_preds, bilstm_test_preds))\n",
    "\n",
    "    # Meta-model prediction\n",
    "    stacking_pred_nn = meta_model.predict(test_preds_meta).flatten()\n",
    "\n",
    "    # --- Compute absolute errors (for MAE-based statistical tests) ---\n",
    "    roberta_errors = np.abs(roberta_test_preds - test_label.values)\n",
    "    bilstm_errors = np.abs(bilstm_test_preds - test_label.values)\n",
    "    ensemble_errors = np.abs(stacking_pred_nn - test_label.values)\n",
    "\n",
    "    # Compute global MAEs just for logging\n",
    "    mae_roberta = mean_absolute_error(test_label, roberta_test_preds)\n",
    "    mae_bilstm = mean_absolute_error(test_label, bilstm_test_preds)\n",
    "    mae_ensemble = mean_absolute_error(test_label, stacking_pred_nn)\n",
    "\n",
    "    print(f\"[{dataset_name}] MAE - RoBERTa: {mae_roberta:.4f}, \"\n",
    "          f\"BiLSTM: {mae_bilstm:.4f}, Ensemble: {mae_ensemble:.4f}\")\n",
    "\n",
    "    # Save predictions + per-instance errors\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'true_storypoint': test_label,\n",
    "        'roberta_pred': roberta_test_preds,\n",
    "        'bilstm_pred': bilstm_test_preds,\n",
    "        'stacking_pred': stacking_pred_nn,\n",
    "        'roberta_error': roberta_errors,\n",
    "        'bilstm_error': bilstm_errors,\n",
    "        'stacking_error': ensemble_errors\n",
    "    })\n",
    "    predictions_df.to_csv(\n",
    "        f'{models_path}/meta-model/{dataset_name}/{dataset_name}_test_predictions.csv',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"Saved test predictions & errors for {dataset_name}\")\n",
    "\n",
    "print(\"All test predictions saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wilcoxon Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# --- Your tokenizer setup (unchanged) ---\n",
    "# roberta_tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "# bilstm_tokenizer = KerasTokenizer(num_words=vocab, oov_token=0)\n",
    "\n",
    "wilcoxon_results = []\n",
    "\n",
    "def vargha_delaney_A12(x, y):\n",
    "    \"\"\"\n",
    "    Vargha & Delaney's A12 effect size (probability of superiority).\n",
    "    Returns probability that a randomly chosen value from x \n",
    "    is greater than a randomly chosen value from y.\n",
    "    For errors (MAE), A12 < 0.5 means x performs better (lower error).\n",
    "    \"\"\"\n",
    "    n_x, n_y = len(x), len(y)\n",
    "    ranks = pd.Series(np.concatenate([x, y])).rank()\n",
    "    r_x = ranks[:n_x].sum()\n",
    "    A12 = (r_x / n_x - (n_x + 1) / 2.0) / n_y\n",
    "    return A12\n",
    "\n",
    "\n",
    "def wilcoxon_with_effects(x, y, alternative=\"less\"):\n",
    "    \"\"\"\n",
    "    Run one-sided Wilcoxon signed-rank test (ensemble vs baseline)\n",
    "    and return statistic, corrected p-value, median difference, and A12.\n",
    "    \"\"\"\n",
    "    # Remove zero differences (Wilcoxon requirement)\n",
    "    diff = x - y\n",
    "    non_zero = diff != 0\n",
    "    x_nz, y_nz = x[non_zero], y[non_zero]\n",
    "    diff_nz = diff[non_zero]\n",
    "\n",
    "    if len(diff_nz) == 0:\n",
    "        return np.nan, np.nan, 0.0, 0.5  # no difference at all\n",
    "\n",
    "    # One-sided Wilcoxon test (ensemble expected < baseline)\n",
    "    stat, p = wilcoxon(x_nz, y_nz, alternative=alternative, zero_method=\"wilcox\")\n",
    "\n",
    "    # Median difference\n",
    "    median_diff = np.median(diff_nz)\n",
    "\n",
    "    # Vargha & Delaney A12\n",
    "    A12 = vargha_delaney_A12(x_nz, y_nz)\n",
    "\n",
    "    return stat, p, median_diff, A12\n",
    "\n",
    "\n",
    "# --- Run tests ---\n",
    "for dataset_name in dataset_names:\n",
    "    print(f\"Processing Wilcoxon test for {dataset_name}...\")\n",
    "\n",
    "    pred_path = f'{models_path}/meta-model/{dataset_name}/{dataset_name}_test_predictions.csv'\n",
    "    if not os.path.exists(pred_path):\n",
    "        print(f\"Prediction file not found for {dataset_name}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(pred_path)\n",
    "    stacking_error = df['stacking_error'].values\n",
    "    roberta_error = df['roberta_error'].values\n",
    "    bilstm_error = df['bilstm_error'].values\n",
    "\n",
    "    # Ensemble vs RoBERTa\n",
    "    stat_ens_rob, p_ens_rob, med_diff_rob, A12_rob = wilcoxon_with_effects(stacking_error, roberta_error)\n",
    "\n",
    "    # Ensemble vs BiLSTM\n",
    "    stat_ens_bilstm, p_ens_bilstm, med_diff_bilstm, A12_bilstm = wilcoxon_with_effects(stacking_error, bilstm_error)\n",
    "\n",
    "    result = {\n",
    "        'dataset': dataset_name,\n",
    "        'wilcoxon_stat_ensemble_vs_roberta': float(stat_ens_rob),\n",
    "        'wilcoxon_p_ensemble_vs_roberta': float(p_ens_rob),\n",
    "        'median_diff_ensemble_vs_roberta': float(med_diff_rob),\n",
    "        'vd_A12_ensemble_vs_roberta': float(A12_rob),\n",
    "\n",
    "        'wilcoxon_stat_ensemble_vs_bilstm': float(stat_ens_bilstm),\n",
    "        'wilcoxon_p_ensemble_vs_bilstm': float(p_ens_bilstm),\n",
    "        'median_diff_ensemble_vs_bilstm': float(med_diff_bilstm),\n",
    "        'vd_A12_ensemble_vs_bilstm': float(A12_bilstm),\n",
    "    }\n",
    "    wilcoxon_results.append(result)\n",
    "\n",
    "    # Save per-dataset result\n",
    "    with open(f'{models_path}/meta-model/{dataset_name}/{dataset_name}_wilcoxon_one_sided.json', 'w') as f:\n",
    "        json.dump(result, f, indent=2)\n",
    "\n",
    "# --- Apply Bonferroni correction ---\n",
    "wilcoxon_df = pd.DataFrame(wilcoxon_results)\n",
    "K = len(wilcoxon_df) * 2  # two tests per dataset\n",
    "print(\"Number of tests (K): \" + str(K))\n",
    "wilcoxon_df['wilcoxon_p_ensemble_vs_roberta_corrected'] = np.minimum(wilcoxon_df['wilcoxon_p_ensemble_vs_roberta'] * K, 1.0)\n",
    "wilcoxon_df['wilcoxon_p_ensemble_vs_bilstm_corrected'] = np.minimum(wilcoxon_df['wilcoxon_p_ensemble_vs_bilstm'] * K, 1.0)\n",
    "\n",
    "# Save all results\n",
    "wilcoxon_df.to_csv(f'{models_path}/meta-model/wilcoxon_results_one_sided.csv', index=False)\n",
    "print(\"One-sided Wilcoxon signed-rank test results saved with median differences and Vargha-Delaney A12 effect sizes (Bonferroni corrected).\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_sp_env_3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
